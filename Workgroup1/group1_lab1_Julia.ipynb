{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata_read = load(\"../../../data/wage2015_subsample_inference.RData\")\n",
    "data = rdata_read[\"data\"]\n",
    "names(data)\n",
    "println(\"Number of Rows : \", size(data)[1],\"\\n\",\"Number of Columns : \", size(data)[2],) #rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad08172",
   "metadata": {},
   "source": [
    "# An inferential problem: The Gender Wage Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac05f6a",
   "metadata": {},
   "source": [
    "In the previous lab, we already analyzed data from the March Supplement of the U.S. Current Population Survey (2015) and answered the question how to use job-relevant characteristics, such as education and experience, to best predict wages. Now, we focus on the following inference question:\n",
    "\n",
    "What is the difference in predicted wages between men and women with the same job-relevant characteristics?\n",
    "\n",
    "Thus, we analyze if there is a difference in the payment of men and women (*gender wage gap*). The gender wage gap may partly reflect *discrimination* against women in the labor market or may partly reflect a *selection effect*, namely that women are relatively more likely to take on occupations that pay somewhat less (for example, school teaching)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbca958",
   "metadata": {},
   "source": [
    "To investigate the gender wage gap, we consider the following log-linear regression model\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &= \\beta'X + \\epsilon\\\\\n",
    "&= \\beta_1 D  + \\beta_2' W + \\epsilon,\n",
    "\\end{align}\n",
    "\n",
    "where $D$ is the indicator of being female ($1$ if female and $0$ otherwise) and the\n",
    "$W$'s are controls explaining variation in wages. Considering transformed wages by the logarithm, we are analyzing the relative difference in the payment of men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5758db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"CategoricalArrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using DataFrames\n",
    "using Dates\n",
    "using Plots\n",
    "using Statistics,RData  #upload data of R format \n",
    "using CategoricalArrays # categorical data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96fd51",
   "metadata": {},
   "source": [
    "***Variable description***\n",
    "\n",
    "- occ : occupational classification\n",
    "- ind : industry classification\n",
    "- lwage : log hourly wage\n",
    "- sex : gender (1 female) (0 male)\n",
    "- shs : some high school\n",
    "- hsg : High school graduated\n",
    "- scl : Some College\n",
    "- clg: College Graduate\n",
    "- ad: Advanced Degree\n",
    "- ne: Northeast\n",
    "- mw: Midwest\n",
    "- so: South\n",
    "- we: West\n",
    "- exp1: experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1666b40",
   "metadata": {},
   "source": [
    "### **1.  Analysis in the subset of workers with advanced college education (variables scl, clg, ad).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a5122",
   "metadata": {},
   "source": [
    "Next, we will conduct an analysis for the subset of workers with advanced college education. To do this, we will restrict our data and keep only those who have Some College, College Graduate, or Advanced Degree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = data[(data[!, :scl] .== 1) .| (data[!, :clg] .== 1) .| (data[!, :ad] .== 1), :]\n",
    "Z = data[(data[!, :scl] .== 1) .| (data[!, :clg] .== 1) .| (data[!, :ad] .== 1), \n",
    "         [:lwage, :sex, :shs, :hsg, :scl, :clg, :ad, :ne, :mw, :so, :we, :exp1]]\n",
    "data_female = data[(data[!, :sex] .== 1) .& ((data[!, :scl] .== 1) .| (data[!, :clg] .== 1) .| (data[!, :ad] .== 1)), :]\n",
    "Z_female = data_female[!, [:lwage, :sex, :shs, :hsg, :scl, :clg, :ad, :ne, :mw, :so, :we, :exp1]]\n",
    "\n",
    "# Filtrar datos para hombres\n",
    "data_male = data[(data[!, :sex] .== 0) .& ((data[!, :scl] .== 1) .| (data[!, :clg] .== 1) .| (data[!, :ad] .== 1)), :]\n",
    "Z_male = data_male[!, [:lwage, :sex, :shs, :hsg, :scl, :clg, :ad, :ne, :mw, :so, :we, :exp1]]\n",
    "\n",
    "means = DataFrame( variables = names(Z), All = describe(Z, :mean)[!,2], Men = describe(Z_male,:mean)[!,2], Female = describe(Z_female,:mean)[!,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690926f0",
   "metadata": {},
   "source": [
    "In particular, the table above shows that the difference in average logwage between men and women is equal to  $0.0750$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Z_female[:,:lwage]) - mean(Z_male[:,:lwage])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970e0dc",
   "metadata": {},
   "source": [
    "Thus, the unconditional gender wage gap is about $7,5$\\% for the group of never married workers (women get paid less on average in our sample). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4937316",
   "metadata": {},
   "source": [
    "#### 1.1 OLS estimation without controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ea7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install all the package that we can need\n",
    "#Pkg.add(\"GLM\") # package to run models \n",
    "#Pkg.add(\"StatsPlots\")\n",
    "#Pkg.add(\"MLBase\")\n",
    "#Pkg.add(\"Tables\")\n",
    "#Pkg.add(\"CovarianceMatrices\") # robust standar error \n",
    "# Load the installed packages\n",
    "using DataFrames\n",
    "using Tables\n",
    "using GLM\n",
    "using CovarianceMatrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocontrol_model = lm(@formula(lwage ~ sex), sub_data)\n",
    "nocontrol_est = GLM.coef(nocontrol_model)[2]\n",
    "nocontrol_se = GLM.coeftable(nocontrol_model).cols[2][2]\n",
    "\n",
    "# nocontrol_se1 = stderror(HC1(), nocontrol_model)[2]\n",
    "CI1upper = confint(nocontrol_model)[2, 2]\n",
    "CI1low = confint(nocontrol_model)[2, 1]\n",
    "\n",
    "println(\"The estimated gender coefficient is \", nocontrol_est ,\" and the corresponding robust standard error is \" ,nocontrol_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee5f3f",
   "metadata": {},
   "source": [
    "#### 1.2 OLS estimation with controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaefaf6",
   "metadata": {},
   "source": [
    "Next, we run an ols regression of $Y$ on $(D,W)$ to control for the effect of covariates summarized in $W$:\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &=\\beta_1 D  + \\beta_2' W + \\epsilon.\n",
    "\\end{align}\n",
    "\n",
    "Here, we are considering the flexible model from the previous lab. Hence, $W$ controls for experience, education, region, and occupation and industry indicators plus transformations and two-way interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adc363",
   "metadata": {},
   "outputs": [],
   "source": [
    "flex = @formula(lwage ~ sex + (exp1+exp2+exp3+exp4) * (shs+hsg+scl+clg+occ2+ind2+mw+so+we))\n",
    "control_model = lm(flex , sub_data)\n",
    "control_est = GLM.coef(control_model)[2]\n",
    "control_se = GLM.coeftable(control_model).cols[2][2]\n",
    "#control_se1 = stderror( HC0(), control_model)[2]\n",
    "CI2upper = confint(control_model)[2, 2]\n",
    "CI2low = confint(control_model)[2, 1]\n",
    "\n",
    "println(\"Coefficient for OLS with controls \" , control_est, \"robust standard error:\", control_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed82d8",
   "metadata": {},
   "source": [
    "#### 1.3 Partialling-Out using ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c23d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# models\n",
    "# model for Y\n",
    "flex_y = @formula(lwage ~ (exp1+exp2+exp3+exp4) * (shs+hsg+scl+clg+occ2+ind2+mw+so+we))\n",
    "flex_d = @formula(sex ~ (exp1+exp2+exp3+exp4) * (shs+hsg+scl+clg+occ2+ind2+mw+so+we))\n",
    "\n",
    "t_Y = residuals(lm(flex_y, sub_data))\n",
    "t_D = residuals(lm(flex_d, sub_data))\n",
    "\n",
    "data_res = DataFrame(t_Y = t_Y, t_D = t_D )\n",
    "partial_fit = lm(@formula(t_Y ~ t_D), data_res)\n",
    "partial_est = GLM.coef(partial_fit)[2]\n",
    "\n",
    "# standard error\n",
    "partial_se = GLM.coeftable(partial_fit).cols[2][2]\n",
    "\n",
    "#partial_se1 = stderror( HC0(), partial_fit)[2]\n",
    "\n",
    "#condifence interval\n",
    "CI3upper = confint(partial_fit)[2, 2]\n",
    "CI3low = confint(partial_fit)[2, 1]\n",
    "println(\"Coefficient for D via partiallig-out \", partial_est, \" robust standard error:\", partial_se )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02383f81",
   "metadata": {},
   "source": [
    "We know that the partialling-out approach works well when the dimension of $W$ is low\n",
    "in relation to the sample size $n$. When the dimension of $W$ is relatively high, we need to use variable selection\n",
    "or penalization for regularization purposes. \n",
    "\n",
    "In the following, we illustrate the partialling-out approach using lasso instead of ols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0893b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(modelos = [ \"Without controls\", \"full reg\", \"partial reg\" ], \n",
    "Estimate = [nocontrol_est,control_est, partial_est], \n",
    "StdError = [nocontrol_se,control_se, partial_se])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf1cde",
   "metadata": {},
   "source": [
    "### **2.   Descriptive statistics subset of workers with advanced college education (variables scl, clg, ad).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a6402",
   "metadata": {},
   "source": [
    "##### 2.1)  Wage & Lwage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a822a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_density = density(data.wage, fillcolor = :blue, fillalpha = 0.5, \n",
    "                        legend = false, title = \"Figure1: Density of wages\",\n",
    "                        xlabel = \"Log Wage\", ylabel = \"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density = density(data.lwage, fillcolor = :blue, fillalpha = 0.5, \n",
    "                        legend = false, title = \"Figure1: Density of wages\",\n",
    "                        xlabel = \"Log Wage\", ylabel = \"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5891a",
   "metadata": {},
   "source": [
    "#### 2.2 Descriptive data by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f84ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Bplot = boxplot(data.lwage, title = \"BoxPlot - Log Wage by Gender\",\n",
    "    ylabel = \"Log Wage\", xlabel = \"Gender\",label = \"All\", legend =:outerright )\n",
    "boxplot!(Z_female.lwage, label = \"Female\" )\n",
    "boxplot!(Z_male.lwage, label = \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf29b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c249a7f",
   "metadata": {},
   "source": [
    "### **3. Confidence Interval of sex's coefficient for a different models:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef83950",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIdf = DataFrame(\n",
    "    x = [\"No Control\", \"With Control\", \"Partialling Out\"],\n",
    "    y = [nocontrol_est, control_est, partial_est],\n",
    "    lower = [CI1low, CI2low, CI3low],\n",
    "    upper = [CI1upper, CI2upper, CI3upper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d60710",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gadfly\n",
    "plot_density =  Gadfly.plot(CIdf, x=:x, y=:y, ymin=:lower, ymax=:upper,\n",
    "                    Geom.point(), Geom.errorbar(),\n",
    "                    Guide.title(\"Figure 9: C.I. of the sex variable according to different estimations.\"),\n",
    "                    Theme(panel_fill=\"white\", panel_stroke=colorant\"black\", default_color=colorant\"darkred\"))\n",
    "display(plot_density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2efa3b0",
   "metadata": {},
   "source": [
    "### **4. Replication of the figure: Experience Profiles and Wage Gap for High School Graduates**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27200cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hsg = data[data.hsg .== 1, :]\n",
    "data_clg = data[data.clg .== 1, :]\n",
    "data_scl = data[data.scl .== 1, :]\n",
    "\n",
    "data_clgm = data_clg[data_clg.sex .== 0, :]  # Hombres\n",
    "data_clgf = data_clg[data_clg.sex .== 1, :]  # Mujeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c138e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla_hsg\n",
    "Tabla_hsg = data_hsg.groupby('exp1').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "nivel_hsg = sorted(data_hsg['exp1'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_hsg:\n",
    "    Promedio.append(data_hsg[data_hsg['exp2'] <= nivel]['lwage'].mean())\n",
    "\n",
    "Tabla_hsg['PromMov'] = Promedio\n",
    "print(Tabla_hsg.head())\n",
    "\n",
    "# Tabla_clg\n",
    "Tabla_clg = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "Tabla_clgm = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "Tabla_clgf = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "\n",
    "nivel_clg = sorted(data_clg['exp2'].unique())\n",
    "nivel_clgm = sorted(data_clgm['exp2'].unique())\n",
    "nivel_clgf = sorted(data_clgf['exp2'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_clg:\n",
    "    Promedio.append(data_clg[data_clg['exp2'] <= nivel]['lwage'].mean())\n",
    "\n",
    "Tabla_clg['PromMov'] = Promedio\n",
    "Tabla_clgm['PromMov'] = Promedio\n",
    "Tabla_clgf['PromMov'] = Promedio\n",
    "print(Tabla_clg.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la fórmula del modelo\n",
    "formula = @formula(lwage ~ sex + (exp1 + exp2 + exp3 + exp4) * (shs + hsg + scl + clg + occ2 + ind2 + mw + so + we))\n",
    "\n",
    "# Ajustar el modelo\n",
    "control_fit1 = lm(formula, data)\n",
    "\n",
    "# Hacer predicciones\n",
    "predict = predict(control_fit1)\n",
    "\n",
    "# Añadir las predicciones al DataFrame original\n",
    "data[!, :Predict] = predict\n",
    "\n",
    "# Filtrar datos para scl y clg\n",
    "data_sclP = filter(row -> row.scl == 1, data)\n",
    "data_clgP = filter(row -> row.clg == 1, data)\n",
    "data_hsgP = filter(row -> row.hsg == 1, data)\n",
    "\n",
    "data_clgPm = filter(row -> row.clg == 1 && row.sex == 0, data)  # Hombres\n",
    "data_clgPf = filter(row -> row.clg == 1 && row.sex == 1, data)  # Mujeres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# Using \"sclP\"\n",
    "Tabla_hsgP = by(data_hsgP, :exp2, Predict = :Predict => mean)\n",
    "Tabla_hsgP = sort!(Tabla_hsgP, :exp2)\n",
    "\n",
    "nivel_hsgP = sort(unique(data_hsgP.exp2))\n",
    "\n",
    "Promedio = [mean(data_hsgP[data_hsgP.exp2 .<= nivel, :Predict]) for nivel in nivel_hsgP]\n",
    "Tabla_hsgP[!, :PromMovP] = Promedio\n",
    "\n",
    "println(first(Tabla_hsgP, 5))\n",
    "\n",
    "# Repeat for \"clgP\"\n",
    "Tabla_clgP = by(data_clgP, :exp2, Predict = :Predict => mean)\n",
    "Tabla_clgP = sort!(Tabla_clgP, :exp2)\n",
    "\n",
    "Tabla_clgPf = by(data_clgPf, :exp2, Predict = :Predict => mean)\n",
    "Tabla_clgPf = sort!(Tabla_clgPf, :exp2)\n",
    "\n",
    "Tabla_clgPm = by(data_clgPm, :exp2, Predict = :Predict => mean)\n",
    "Tabla_clgPm = sort!(Tabla_clgPm, :exp2)\n",
    "\n",
    "nivel_clgP = sort(unique(data_clgP.exp2))\n",
    "\n",
    "Promedio = [mean(data_clgP[data_clgP.exp2 .<= nivel, :Predict]) for nivel in nivel_clgP]\n",
    "Tabla_clgP[!, :PromMov] = Promedio\n",
    "Tabla_clgPf[!, :PromMov] = Promedio\n",
    "\n",
    "Promediof = Promedio[1:end-1]\n",
    "Tabla_clgPm[!, :PromMov] = Promediof\n",
    "\n",
    "println(first(Tabla_clgP, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d718da",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Datos\n",
    "x = Tabla_clg[:exp2]\n",
    "x_3 = Tabla_clgPm[:exp2]\n",
    "y = Tabla_clg[:PromMov]\n",
    "y_3 = Tabla_clgPm[:PromMov]\n",
    "\n",
    "# Crear el gráfico\n",
    "plot(x, y, color=:navy, linestyle=:solid, label=\"Actual CLG\")\n",
    "plot!(x_3, y_3, color=:darkred, linestyle=:dash)\n",
    "\n",
    "# Ajustes del gráfico\n",
    "ylims!(3, 3.2)\n",
    "xlims!(0, 15)\n",
    "xlabel!(\"Years of Potential Experience\")\n",
    "ylabel!(\"Log Wage (or Wage Gap)\")\n",
    "title!(\"Comparison between actual and fitted for CLG and HSG Male\")\n",
    "grid!(linestyle=:dash, color=:gray)\n",
    "\n",
    "# Marcas de los ejes\n",
    "xticks!(0:5:15)\n",
    "\n",
    "# Leyenda\n",
    "legend!(:topright, fontsize=8)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "display(plot!())\n",
    "\n",
    "# Datos\n",
    "x = Tabla_clg[:exp2]\n",
    "x_3 = Tabla_clgPf[:exp2]\n",
    "y = Tabla_clg[:PromMov]\n",
    "y_3 = Tabla_clgPf[:PromMov]\n",
    "\n",
    "# Crear el gráfico\n",
    "plot(x, y, color=:navy, linestyle=:solid, label=\"Actual CLG\")\n",
    "plot!(x_3, y_3, color=:darkred, linestyle=:dash)\n",
    "\n",
    "# Ajustes del gráfico\n",
    "ylims!(3, 3.2)\n",
    "xlims!(0, 15)\n",
    "xlabel!(\"Years of Potential Experience\")\n",
    "ylabel!(\"Log Wage (or Wage Gap)\")\n",
    "title!(\"Comparison between actual and fitted for CLG and HSG Female\")\n",
    "grid!(linestyle=:dash, color=:gray)\n",
    "\n",
    "# Marcas de los ejes\n",
    "xticks!(0:5:15)\n",
    "\n",
    "# Leyenda\n",
    "legend!(:topright, fontsize=8)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "display(plot!())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9bfdd-f690-475b-8f20-d864427811c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añadiendo los paquetes necesarios\n",
    "using Pkg\n",
    "Pkg.add(\"GLM\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"DelimitedFiles\")\n",
    "Pkg.add(\"RData\")\n",
    "Pkg.add(\"Random\")\n",
    "Pkg.add(\"Lasso\")\n",
    "Pkg.add(\"DataStructures\")\n",
    "Pkg.add(\"NamedArrays\")\n",
    "Pkg.add(\"PrettyTables\")\n",
    "Pkg.add(\"Plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903cdc3-e321-4bd5-866d-63bd51e2fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLM, DataFrames, Random, RData, Lasso, LinearAlgebra, Statistics, DataStructures, NamedArrays, PrettyTables, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e41e68-a637-4359-b914-b463ab0cdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carpeta Inicio\n",
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da256728-9ae2-4caf-8ccb-63481d132dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Reading the Data\n",
    "Data = load(\"wage2015_subsample_inference.Rdata\")\n",
    "Data = Data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7764dc5-4d41-48d9-b6aa-d4c185fc2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Setting the Alpha Vector\n",
    "Alpha_Vector = [0.1, 0.2,0.3,0.4,0.5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d069a24-d43c-4f1f-b568-f690584752ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3. Shuffle and Folds Generation\n",
    "Random.seed!(123)  # Set a random seed for reproducibility\n",
    "Data_Shuffled = shuffle!(Data)\n",
    "k_folds = 10\n",
    "Fold_Size = Int.(Total_Observations / k_folds)\n",
    "Fold_List = []\n",
    "\n",
    "for number in 1:k_folds\n",
    "    Fold_Generation = (Data_Shuffled[1+Fold_Size*(number-1):Fold_Size*(number),:])\n",
    "    push!(Fold_List, Fold_Generation)\n",
    "end\n",
    "\n",
    "Validation_fold = Fold_List[10]\n",
    "Training_Folds = Fold_List[1:9,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2181f847-af39-4b76-80b2-a3bce4ea8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e5ba9-2a42-4b00-85f0-4fa82946ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Lasso Function\n",
    "\n",
    "function lasso_implementation(dataframe, tested, alpha_value)\n",
    "    Y = dataframe[!,\"wage\"]\n",
    "    Y = DataFrame([Y],[:Y])\n",
    "    D = dataframe[!,\"sex\"]\n",
    "    D = DataFrame([D],[:D])\n",
    "    W = select(dataframe, Not([\"lwage\",\"wage\", \"sex\",\"occ\",\"occ2\",\"ind\",\"ind2\"]))\n",
    "    data = [Y D W]\n",
    "    lasso_model = fit(LassoModel, term(:Y) ~  sum(term.(names(data[!, Not([\"Y\", \"D\"])]))), data; α = alpha_value)\n",
    "    Y = tested[!,\"wage\"]\n",
    "    Y = DataFrame([Y],[:Y])\n",
    "    D = tested[!,\"sex\"]\n",
    "    D = DataFrame([D],[:D])\n",
    "    W = select(tested, Not([\"lwage\",\"wage\", \"sex\",\"occ\",\"occ2\",\"ind\",\"ind2\"]))\n",
    "    data_tested = [D W]\n",
    "    Y_predict = predict(lasso_model, data_tested)\n",
    "    Y = tested[!,\"wage\"]\n",
    "    MSE = mean((Y_predict .- Y).^2)\n",
    "    return MSE, lasso_model\n",
    "end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d297c77-e893-48a0-b6f1-dc5f1983b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Cross Validation\n",
    "MSE_Averages = []\n",
    "for alpha in Alpha_Vector\n",
    "    MSE_List = []\n",
    "    for i in 1:k_folds-1\n",
    "        tested_fold = Training_Folds[i,:][1]\n",
    "        Current_Folds = [Training_Folds[z] for z in 1:length(Training_Folds) if !(z == i)]\n",
    "        Combined_dataframe = vcat(Current_Folds...)\n",
    "        MSE_current = lasso_implementation(Combined_dataframe,tested_fold,alpha)\n",
    "        push!(MSE_List, MSE_current[1])\n",
    "    end\n",
    "    MSE_Mean = mean(MSE_List)\n",
    "    println(\"MSE for this alpha \",alpha,\": \",MSE_Mean)\n",
    "    Alpha_MSE = [MSE_Mean, alpha]\n",
    "    push!(MSE_Averages, Alpha_MSE)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481b251-27d3-4102-8d4a-5be808f0a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Selecting Optimal Alpha\n",
    "\n",
    "MSE_Averages_Final = []\n",
    "for i in MSE_Averages\n",
    "    push!(MSE_Averages_Final, i[1])\n",
    "end\n",
    "min_value = minimum(MSE_Averages_Final)\n",
    "index = findfirst(x -> x == min_value, MSE_Averages_Final)\n",
    "\n",
    "Optimal_Alpha = MSE_Averages[index][2]\n",
    "println(\"Optimal Alpha: \",Optimal_Alpha)\n",
    "println(\"Optimal MSE: \",MSE_Averages[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538275a-f4d5-4f45-8ba0-4c27fd0f28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Final Training Set\n",
    "Combined_dataframe = vcat(Training_Folds...)\n",
    "Last_Alpha = lasso_implementation(Combined_dataframe, Validation_fold, Optimal_Alpha)\n",
    "MSE = Last_Alpha[1]\n",
    "println(\"Final MSE: \", MSE)\n",
    "\n",
    "#Due to the lower MSE we can say that this model can be generalized and be more useful for prediction than otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2e996-9c05-44e8-afbb-0734b7d48e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Plotting\n",
    "plot(Alpha_Vector, MSE_Averages_Final, xlabel=\"Alpha\", ylabel=\"MSE\", title=\"Cross-Validation\", label=\"Data\", marker=:circle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1a646-d8b1-4888-b9ee-d606c3d79a72",
   "metadata": {},
   "source": [
    "# **1.Frisch-Waugh-Lovell (FWL) Theorem Proof**\n",
    "\n",
    "Given a linear regression model, we aim to demonstrate the FWL theorem using the following elements:\n",
    "\n",
    "- **$y$**: dependent variable vector ($n \\times 1$)\n",
    "- **$D$**: matrix of independent variables of interest ($n \\times k_1$)\n",
    "- **$\\beta_1$**: coefficient vector for $D$ ($k_1 \\times 1$)\n",
    "- **$W$**: matrix of control variables ($n \\times k_2$)\n",
    "- **$\\beta_2$**: coefficient vector for $W$ ($k_2 \\times 1$)\n",
    "- **$u$**: error term vector ($n \\times 1$)\n",
    "\n",
    "The model is represented as:\n",
    "\n",
    "$$ y = D\\beta_1 + W\\beta_2 + u$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "To prove that $\\Psi = \\beta_1$ can be accurately estimated through the regression $e_y = e_D \\Psi + \\varepsilon$, employing the FWL theorem.\n",
    "\n",
    "---\n",
    "\n",
    "## **Proof**\n",
    "\n",
    "### **Step 1: Control for Variables in $W$**\n",
    "\n",
    "First, we calculate the residuals after controlling for $W$:\n",
    "\n",
    "- **Regress $D$ on $W$:** Aim to determine the component of $D$ that is orthogonal to $W$. This is achieved by calculating the residuals $e_D$, using the projection matrix:\n",
    "  \n",
    "  $$M_W = I - W(W'W)^{-1}W'$$\n",
    "  \n",
    "  Thus, the residuals for $D$ are:\n",
    "  \n",
    "  $$e_D = M_W D$$ \n",
    "\n",
    "- **Regress $y$ on $W$:** Similarly, find the component of $y$ not explained by $W$:\n",
    "  \n",
    "  $$e_y = M_W y$$\n",
    "\n",
    "### **Step 2: Estimate $\\Psi$**\n",
    "\n",
    "With the residuals obtained, we proceed to estimate $\\Psi$:\n",
    "\n",
    "- **Regress $e_y$ on $e_D$ by OLS:** \n",
    "\n",
    "  $$ e_y = e_D \\Psi + z $$\n",
    "  \n",
    "  Solving for $\\Psi$, we get:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (e_D'e_D)^{-1}e_D'e_y $$\n",
    "  \n",
    "  Substituting the expressions for residuals into $\\hat{\\Psi}$ yields:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (D'M_W'M_W'D)^{-1}D'M_W'M_Wy $$\n",
    "  \n",
    "  Which simplifies to:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (D'M_WD)^{-1}D'M_Wy $$\n",
    "\n",
    "And this proof that $\\Psi = \\beta_1$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# **2.Conditional Expectation Function Minimizes Expected Squared Error Proof**\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "Given a random variable $Y$ and a conditioning variable $X$, we consider a relationship of the form:\n",
    "$$ Y = m(X) + \\epsilon $$\n",
    "where:\n",
    "- $m(X) = E[Y | X]$ is the Conditional Expectation Function (CEF) of $Y$ given $X$.\n",
    "- $\\epsilon$ is the error term, representing the deviation of $Y$ from its conditional mean.\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "Our goal is to prove that the function that minimizes the expected squared error:\n",
    "$$ m(X) = \\text{arg}\\min_{g(X)} E[(Y - g(X))^2] $$\n",
    "\n",
    "is indeed:\n",
    "$$ E[(Y - g(X))^2] = E[\\epsilon^2] $$\n",
    "\n",
    "## **Proof**\n",
    "\n",
    "### **Step 1: Expanding the Expected Squared Error**\n",
    "\n",
    "We start by expanding the expected squared difference as follows:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X] + E[Y|X] - g(X))^2] $$\n",
    "\n",
    "By applying the expansion for the square of a sum $(a + b)^2 = a^2 + b^2 + 2ab$, where $a = Y - E[Y|X]$ and $b = E[Y|X] - g(X)$, we obtain:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X])^2] + E[(E[Y|X] - g(X))^2] + 2E[(Y - E[Y|X])(E[Y|X] - g(X))] $$\n",
    "\n",
    "### **Step 2: Simplifying Using the Law of Iterated Expectations**\n",
    "\n",
    "Applying the Law of Iterated Expectations to the mixed term:\n",
    "$$ 2E[(Y - E[Y|X])(E[Y|X] - g(X))] = 0 $$\n",
    "\n",
    "This follows because the expectation of $Y - E[Y|X]$ is zero by definition of the error term $\\epsilon$ (i.e., $Y - E[Y|X] = \\epsilon$ and $E[\\epsilon] = 0$), and thus the cross-term disappears.\n",
    "\n",
    "### **Step 3: Final Reduction**\n",
    "\n",
    "After removing the cross-term, we are left with:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X])^2] + E[(E[Y|X] - g(X))^2] $$\n",
    "\n",
    "Since the second term $E[(E[Y|X] - g(X))^2]$ is always non-negative, it follows that:\n",
    "$$ E[(Y - g(X))^2] \\geq E[(Y - E[Y|X])^2] $$\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "The expected squared error is minimized when $g(X) = E[Y|X]$, demonstrating that the Conditional Expectation Function (CEF) $m(X)$ minimizes the expected squared error:\n",
    "$$ m(X) = \\text{arg}\\min_{g(X)} E[(Y - g(X))^2] $$\n",
    "This conclusively proves that the CEF is the function that minimizes the expected squared error between the predicted values and the actual values of $Y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826c37d-777c-492a-8099-81249d4c0dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
