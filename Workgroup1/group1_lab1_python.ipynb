{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e829e69",
   "metadata": {
    "papermill": {
     "duration": 0.018579,
     "end_time": "2021-02-21T17:17:47.809138",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.790559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# An inferential problem: The Gender Wage Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c3651",
   "metadata": {
    "papermill": {
     "duration": 0.018169,
     "end_time": "2021-02-21T17:17:47.921363",
     "exception": false,
     "start_time": "2021-02-21T17:17:47.903194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d67cc",
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr as rr # package to use data form R format\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyreadr==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96f8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rdata_read = pyreadr.read_r(\"../../data/wage2015_subsample_inference.Rdata\")\n",
    "\n",
    "data  = pd.read_csv(r'C:/Users/Frank/Downloads/wage2015_subsample_inference.csv')\n",
    "\n",
    "# Extracting the data frame from rdata_read\n",
    "#data = rdata_read[ 'data' ]\n",
    "data['occ']=pd.Categorical(data.occ)\n",
    "data['occ2']=pd.Categorical(data.occ2)\n",
    "data['ind']=pd.Categorical(data.ind)\n",
    "data['ind2']=pd.Categorical(data.ind2)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6df84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad65b36",
   "metadata": {},
   "source": [
    "***Variable description***\n",
    "\n",
    "- occ : occupational classification\n",
    "- ind : industry classification\n",
    "- lwage : log hourly wage\n",
    "- sex : gender (1 female) (0 male)\n",
    "- shs : some high school\n",
    "- hsg : High school graduated\n",
    "- scl : Some College\n",
    "- clg: College Graduate\n",
    "- ad: Advanced Degree\n",
    "- ne: Northeast\n",
    "- mw: Midwest\n",
    "- so: South\n",
    "- we: West\n",
    "- exp1: experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135af855",
   "metadata": {},
   "source": [
    "In this case, we Focus on the subset of college-advanced-educated workers. he analysis should be analogous to what we’ve presented – explaining basic, control and partialling out model, generating point estimates and standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44722ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.scl == 1) | (data.ad == 1) | (data.clg == 1)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e82254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f652de",
   "metadata": {
    "papermill": {
     "duration": 0.020145,
     "end_time": "2021-02-21T17:17:48.235598",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.215453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To start our (causal) analysis, we compare the sample means given gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfa857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z = data[ [\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\"] ]\n",
    "\n",
    "data_female = data[data[ 'sex' ] == 1 ]\n",
    "Z_female = data_female[ [\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\"] ]\n",
    "\n",
    "data_male = data[ data[ 'sex' ] == 0 ]\n",
    "Z_male = data_male[ [ \"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"ne\",\"mw\",\"so\",\"we\",\"exp1\" ] ]\n",
    "\n",
    "\n",
    "table = np.zeros( (12, 3) )\n",
    "table[:, 0] = Z.mean().values\n",
    "table[:, 1] = Z_male.mean().values\n",
    "table[:, 2] = Z_female.mean().values\n",
    "table_pandas = pd.DataFrame( table, columns = [ 'All', 'Men', 'Women']) # from table to dataframe\n",
    "table_pandas.index = [\"Log Wage\",\"Sex\",\"Some High School\",\"High School Graduate\",\"Some College\",\"Gollage Graduate\",\"Advanced Degree\", \"Northeast\",\"Midwest\",\"South\",\"West\",\"Experience\"]\n",
    "table_html = table_pandas.to_html() # html format\n",
    "\n",
    "table_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( table_html )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b70b3",
   "metadata": {
    "papermill": {
     "duration": 0.020634,
     "end_time": "2021-02-21T17:17:48.532828",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.512194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In particular, the table above shows that the difference in average logwage between men and women is equal to  0,075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808bf26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_female['lwage'].mean()- data_male['lwage'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7c945",
   "metadata": {
    "papermill": {
     "duration": 0.022161,
     "end_time": "2021-02-21T17:17:48.635417",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.613256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thus, the unconditional gender wage gap is about 7.5% for the group of never married workers (women get paid less on average in our sample). We also observe that never married working women are relatively more educated than working men and have lower working experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f59847",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata_read = rr.read_r(r\"../../../data/wage2015_subsample_inference.Rdata\")\n",
    "\n",
    "xx\n",
    "# Extracting the data frame from rdata_read\n",
    "data = rdata_read[ 'data' ]\n",
    "\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d9804",
   "metadata": {
    "papermill": {
     "duration": 0.02073,
     "end_time": "2021-02-21T17:17:48.677447",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.656717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This unconditional (predictive) effect of gender equals the coefficient $\\beta$ in the univariate ols regression of $Y$ on $D$:\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &=\\beta D + \\epsilon.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecda80",
   "metadata": {
    "papermill": {
     "duration": 0.020929,
     "end_time": "2021-02-21T17:17:48.718630",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.697701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We verify this by running an ols regression in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f05970",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94a1e5",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1828275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nocontrol_model = smf.ols( formula = 'lwage ~ sex', data = data )\n",
    "nocontrol_est = nocontrol_model.fit().summary2().tables[1]['Coef.']['sex']\n",
    "nocontrol_est\n",
    "nocontrol_se2 = nocontrol_model.fit().summary2().tables[1]['Std.Err.']['sex']\n",
    "\n",
    "\n",
    "# robust standar erros\n",
    "HCV_coefs = nocontrol_model.fit().cov_HC0\n",
    "nocontrol_se = np.power( HCV_coefs.diagonal() , 0.5)[1]\n",
    "nocontrol_se\n",
    "\n",
    "# print unconditional effect of gender and the corresponding standard error\n",
    "\n",
    "print( f'The estimated gender coefficient is {nocontrol_est} and the corresponding standard error is {nocontrol_se2}' )\n",
    "print( f'The estimated gender coefficient is {nocontrol_est} and the corresponding robust standard error is {nocontrol_se}','\\n' )\n",
    "\n",
    "\n",
    "# confidence interval\n",
    "nocontrol_model.fit().conf_int( alpha=0.05 ).loc[['sex']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080d8e8",
   "metadata": {
    "papermill": {
     "duration": 0.02196,
     "end_time": "2021-02-21T17:17:48.991015",
     "exception": false,
     "start_time": "2021-02-21T17:17:48.969055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the standard error is computed with the *R* package *sandwich* to be robust to heteroskedasticity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9839a3",
   "metadata": {
    "papermill": {
     "duration": 0.021605,
     "end_time": "2021-02-21T17:17:49.034485",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.012880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we run an ols regression of $Y$ on $(D,W)$ to control for the effect of covariates summarized in $W$:\n",
    "\n",
    "\\begin{align}\n",
    "\\log(Y) &=\\beta_1 D  + \\beta_2' W + \\epsilon.\n",
    "\\end{align}\n",
    "\n",
    "Here, we are considering the flexible model from the previous lab. Hence, $W$ controls for experience, education, region, and occupation and industry indicators plus transformations and two-way interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891c5e1",
   "metadata": {
    "papermill": {
     "duration": 0.021109,
     "end_time": "2021-02-21T17:17:49.076809",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.055700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us run the ols regression with controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a90cf0",
   "metadata": {},
   "source": [
    "## Ols regression with controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flex = 'lwage ~ sex + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\n",
    "\n",
    "# The smf api replicates R script when it transform data\n",
    "control_model = smf.ols( formula = flex, data = data )\n",
    "control_est = control_model.fit().summary2().tables[1]['Coef.']['sex']\n",
    "\n",
    "print(control_model.fit().summary2().tables[1])\n",
    "\n",
    "HCV_coefs = control_model.fit().cov_HC0\n",
    "control_se = np.power( HCV_coefs.diagonal() , 0.5)[42]  # error standard for sex's coefficients \n",
    "\n",
    "control_se\n",
    "\n",
    "print( f\"Coefficient for OLS with controls {control_est} and the corresponding robust standard error is {control_se}\" )\n",
    "\n",
    "# confidence interval\n",
    "control_model.fit().conf_int( alpha=0.05 ).loc[['sex']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1611bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "control_model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdb6b7",
   "metadata": {
    "papermill": {
     "duration": 0.040523,
     "end_time": "2021-02-21T17:17:49.873210",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.832687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The estimated regression coefficient  𝛽1≈−0.0676 measures how our linear prediction of wage changes if we set the gender variable  𝐷 from 0 to 1, holding the controls  𝑊 fixed. We can call this the predictive effect (PE), as it measures the impact of a variable on the prediction we make. Overall, we see that the unconditional wage gap of size  8 % for women decreases to about  7\n",
    " % after controlling for worker characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881563e",
   "metadata": {
    "papermill": {
     "duration": 0.023222,
     "end_time": "2021-02-21T17:17:49.931749",
     "exception": false,
     "start_time": "2021-02-21T17:17:49.908527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we are using the Frisch-Waugh-Lovell theorem from the lecture partialling-out the linear effect of the controls via ols."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ed949",
   "metadata": {},
   "source": [
    "## Partialling-Out using ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# model for Y\n",
    "flex_y = 'lwage ~  (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\n",
    "# model for D\n",
    "flex_d = 'sex ~ (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)' \n",
    "\n",
    "# partialling-out the linear effect of W from Y\n",
    "t_Y = smf.ols( formula = flex_y , data = data ).fit().resid\n",
    "\n",
    "# partialling-out the linear effect of W from D\n",
    "t_D = smf.ols( formula = flex_d , data = data ).fit().resid\n",
    "\n",
    "\n",
    "data_res = pd.DataFrame( np.vstack(( t_Y.values , t_D.values )).T , columns = [ 't_Y', 't_D' ] )\n",
    "\n",
    "\n",
    "# regression of Y on D after partialling-out the effect of W\n",
    "partial_fit =  smf.ols( formula = 't_Y ~ t_D' , data = data_res ).fit()\n",
    "partial_est = partial_fit.summary2().tables[1]['Coef.']['t_D']\n",
    "\n",
    "\n",
    "# standard error\n",
    "HCV_coefs = partial_fit.cov_HC0\n",
    "partial_se = np.power( HCV_coefs.diagonal() , 0.5)[1]\n",
    "\n",
    "print( f\"Coefficient for D via partialling-out {partial_est} and the corresponding robust standard error is {partial_se}\" )\n",
    "\n",
    "# confidence interval\n",
    "partial_fit.conf_int( alpha=0.05 ).loc[['t_D']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1296ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.vstack(( t_Y.values , t_D.values )).T\n",
    "\n",
    "data_res = pd.DataFrame( np.vstack(( t_Y.values , t_D.values )).T , columns = [ 't_Y', 't_D' ] )\n",
    "data_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce3c43",
   "metadata": {
    "papermill": {
     "duration": 0.023907,
     "end_time": "2021-02-21T17:17:50.458203",
     "exception": false,
     "start_time": "2021-02-21T17:17:50.434296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, the estimated coefficient measures the linear predictive effect (PE) of $D$ on $Y$ after taking out the linear effect of $W$ on both of these variables. This coefficient equals the estimated coefficient from the ols regression with controls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868fcc5",
   "metadata": {
    "papermill": {
     "duration": 0.024507,
     "end_time": "2021-02-21T17:17:50.507023",
     "exception": false,
     "start_time": "2021-02-21T17:17:50.482516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We know that the partialling-out approach works well when the dimension of $W$ is low\n",
    "in relation to the sample size $n$. When the dimension of $W$ is relatively high, we need to use variable selection\n",
    "or penalization for regularization purposes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd04e37",
   "metadata": {},
   "source": [
    "Use appropiate plots (i.e hist, barplots, scatter plots , pie plots, etc) to describe main varaibles (wage, log-wage, sex, some college, college graduate, avdanced degree, Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a92c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "box = sns.boxplot(x=\"sex\", y=\"lwage\", data=data ,palette='pastel')\n",
    "plt.xlabel('Sexo')\n",
    "plt.ylabel('Logaritmo del salario por hora')\n",
    "\n",
    "# The real wage quartiles are increasing with the educational level.\n",
    "# Lower salary dispersion for the postgraduate level. pastel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ddb89",
   "metadata": {},
   "source": [
    "El promedio del logaritmo del salario es mayor para los hombres que para las mujeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d1392",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['wage'].plot(kind = 'hist', bins = 50, figsize = (8,6))\n",
    "plt.title('Salario por hora')\n",
    "\n",
    "txt=\"Elaboración propia\"  \n",
    "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "plt.xlim(0, 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5371b",
   "metadata": {},
   "source": [
    "El salario por hora mas frecuente es el de 20 y hay una distribucion con cola a la izquierda. El salario mas alto es el de 130."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ce1e4",
   "metadata": {},
   "source": [
    "Para las mujeres, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580dce1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=data, x=\"exp1\", y=\"lwage\", x_bins=np.arange(0, 40, 5), order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22780e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#A mas anos de experiencia, las personas consiguen un mayor salario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9f64c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "gridobj = sns.lmplot(x=\"exp1\", y=\"lwage\", \n",
    "                     data=data, \n",
    "                     height=7, \n",
    "                     robust=True, \n",
    "                     palette='Set1', \n",
    "                     col=\"sex\",\n",
    "                     scatter_kws=dict(s=60, linewidths=0.7, edgecolors='black'))\n",
    "\n",
    "gridobj.set(xlim=(0, 80), ylim=(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b28e5d",
   "metadata": {},
   "source": [
    "A simple vista, se ve que la experiencia impacta positivamente en el salario. Pero, en las mujeres ese efecto es menor que en los hombres debido a las brechas de genero persistentes en el mercado laboral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee29fa1",
   "metadata": {},
   "source": [
    "Plot the confidence Interval of sex's coefficient for a different models (basic, control, and partially out). All three coefficients must be in one figure. Explain what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'coef': [nocontrol_est, control_est, partial_est],\n",
    "    'err': [nocontrol_se2, control_se, partial_se],\n",
    "    'varname': ['No control', 'Con controles', 'Parcialmente fuera']\n",
    "})\n",
    "\n",
    "# Reorganizar las columnas\n",
    "coef_df = coef_df[['coef', 'err', 'varname']]\n",
    "\n",
    "# Mostrar el dataframe\n",
    "print(coef_df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "coef_df.plot(x='varname', y='coef', kind='bar', \n",
    "             ax=ax, color='none', \n",
    "             yerr='err', legend=False)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('')\n",
    "ax.scatter(x=pd.np.arange(coef_df.shape[0]), \n",
    "           marker='s', s=120, \n",
    "           y=coef_df['coef'], color='black')\n",
    "ax.axhline(y=0, linestyle='--', color='black', linewidth=4)\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "_ = ax.set_xticklabels(['No control', 'Con controles', 'Parcialmente fuera'], \n",
    "                       rotation=0, fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec33db4",
   "metadata": {},
   "source": [
    "Los coeficientes son mayores para los modelos de Con controles y parcialmente fuera, cuando se restringe la muestra para las personas con educacion avanzada. Asimismo, el error se minimiza cuandos ewe usan los dos ultimos mnodelos, por lo que el intervalo de confianza es menor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29b141",
   "metadata": {},
   "source": [
    "You will also include a replication of the next figure for both groups, female and male.You will have only two plotted lines (Actual/Predicted(fitted)) for these College-educated workers. You have to create two separate figures, one for female and one for male. Could you explain the different patterns that you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Los patrones que se encuentran son que los salarios son mayores para las personas que asisten a la universidad que de los que asisten solo a la secundaria. Luego, la relacion de los anos de experiencia en el salario solo es positiva, tanto para universidad y secundaria, hasta antes de que se llegue a los 35 anos de experiencia.\n",
    "\n",
    "\n",
    "data_hsg = data[data['hsg'] == 1]\n",
    "data_clg = data[data['clg'] == 1]\n",
    "data_scl = data[data['scl'] == 1]\n",
    "\n",
    "data_clgm = data_clg[data_clg['sex'] == 0]  # Hombres\n",
    "data_clgf = data_clg[data_clg['sex'] == 1]  # Mujeres\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Tabla_hsg\n",
    "Tabla_hsg = data_hsg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "\n",
    "nivel_hsg = sorted(data_hsg['exp2'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_hsg:\n",
    "    Promedio.append(data_hsg[data_hsg['exp2'] <= nivel]['lwage'].mean())\n",
    "\n",
    "Tabla_hsg['PromMov'] = Promedio\n",
    "print(Tabla_hsg.head())\n",
    "\n",
    "# Tabla_clg\n",
    "Tabla_clg = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "\n",
    "Tabla_clgm = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "Tabla_clgf = data_clg.groupby('exp2').agg(Promlwageo=('lwage', 'mean')).reset_index()\n",
    "\n",
    "nivel_clg = sorted(data_clg['exp2'].unique())\n",
    "nivel_clgm = sorted(data_clgm['exp2'].unique())\n",
    "nivel_clgf = sorted(data_clgf['exp2'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_clg:\n",
    "    Promedio.append(data_clg[data_clg['exp2'] <= nivel]['lwage'].mean())\n",
    "\n",
    "Tabla_clg['PromMov'] = Promedio\n",
    "Tabla_clgm['PromMov'] = Promedio\n",
    "Tabla_clgf['PromMov'] = Promedio\n",
    "print(Tabla_clg.head())\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Definir la fórmula del modelo\n",
    "formula = 'lwage ~ sex + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\n",
    "\n",
    "# Ajustar el modelo\n",
    "control_fit1 = sm.formula.ols(formula, data=data).fit()\n",
    "\n",
    "# Hacer predicciones\n",
    "predict = control_fit1.predict(data)\n",
    "\n",
    "# Añadir las predicciones al DataFrame original\n",
    "data['Predict'] = predict\n",
    "\n",
    "# Filtrar datos para scl y clg\n",
    "data_sclP = data[data['scl'] == 1]\n",
    "data_clgP = data[data['clg'] == 1]\n",
    "data_hsgP = data[data['hsg'] == 1]\n",
    "\n",
    "data_clgPm = data_clgP[data_clgP['sex'] == 0]  # Hombres\n",
    "data_clgPf = data_clgP[data_clgP['sex'] == 1]  # Mujeres\n",
    "\n",
    "import pandas as pd\n",
    "###########################################################\n",
    "# Using \"sclP\"\n",
    "Tabla_hsgP = data_hsgP.groupby('exp2')['Predict'].mean().reset_index()\n",
    "\n",
    "nivel_hsgP = sorted(data_hsgP['exp2'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_hsgP:\n",
    "    Promedio.append(data_hsgP[data_hsgP['exp2'] <= nivel]['Predict'].mean())\n",
    "\n",
    "Tabla_hsgP['PromMovP'] = Promedio\n",
    "print(Tabla_hsgP.head())\n",
    "\n",
    "# Repeat for \"clgP\"\n",
    "Tabla_clgP = data_clgP.groupby('exp2')['Predict'].mean().reset_index()\n",
    "Tabla_clgPf = data_clgPf.groupby('exp2')['Predict'].mean().reset_index()\n",
    "Tabla_clgPm = data_clgPm.groupby('exp2')['Predict'].mean().reset_index()\n",
    "\n",
    "nivel_clgP = sorted(data_clgP['exp2'].unique())\n",
    "\n",
    "Promedio = []\n",
    "for nivel in nivel_clgP:\n",
    "    Promedio.append(data_clgP[data_clgP['exp2'] <= nivel]['Predict'].mean())\n",
    "\n",
    "Tabla_clgP['PromMov'] = Promedio\n",
    "Tabla_clgPf['PromMov'] = Promedio\n",
    "\n",
    "Promediof = Promedio[:-1]\n",
    "Tabla_clgPm['PromMov'] = Promediof\n",
    "print(Tabla_clgP.head())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos\n",
    "x = Tabla_clg['exp2']\n",
    "x_3 = Tabla_clgPm['exp2']\n",
    "y = Tabla_clg['PromMov']\n",
    "y_3 = Tabla_clgPm['PromMov']\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.plot(x, y, color='navy', linestyle='-', label=\"Actual CLG\")\n",
    "\n",
    "plt.plot(x_3, y_3, color='darkred', linestyle='--')\n",
    "\n",
    "# Ajustes del gráfico\n",
    "plt.ylim(3, 3.2)\n",
    "plt.xlim(0, 15)\n",
    "plt.xlabel(\"Years of Potential Experience\")\n",
    "plt.ylabel(\"Log Wage (or Wage Gap)\")\n",
    "plt.title(\"Figure 10: Comparison between actual and fitted for CLG and HSG Male\")\n",
    "plt.grid(linestyle='--', color='gray')\n",
    "\n",
    "# Marcas de los ejes\n",
    "plt.xticks(range(0, 16, 5))\n",
    "\n",
    "# Leyenda\n",
    "plt.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "# Datos\n",
    "x = Tabla_clg['exp2']\n",
    "x_3 = Tabla_clgPf['exp2']\n",
    "y = Tabla_clg['PromMov']\n",
    "y_3 = Tabla_clgPf['PromMov']\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.plot(x, y, color='navy', linestyle='-', label=\"Actual CLG\")\n",
    "\n",
    "plt.plot(x_3, y_3, color='darkred', linestyle='--')\n",
    "\n",
    "# Ajustes del gráfico\n",
    "plt.ylim(3, 3.2)\n",
    "plt.xlim(0, 15)\n",
    "plt.xlabel(\"Years of Potential Experience\")\n",
    "plt.ylabel(\"Log Wage (or Wage Gap)\")\n",
    "plt.title(\"Figure 10: Comparison between actual and fitted for CLG and HSG Female\")\n",
    "plt.grid(linestyle='--', color='gray')\n",
    "\n",
    "# Marcas de los ejes\n",
    "plt.xticks(range(0, 16, 5))\n",
    "\n",
    "# Leyenda\n",
    "plt.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298fb90",
   "metadata": {},
   "source": [
    "Los patrones que se encuentran son que los salarios son mayores para las personas que asisten a la universidad que de los que asisten solo a la secundaria. Luego, la relacion de los anos de experiencia en el salario solo es positiva, tanto para universidad y secundaria, hasta antes de que se llegue a los 35 anos de experiencia. Luego, si diferenciamos entre sexo la diferencia es muy pequeña."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03b4e7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Now, we will construct a prediction rule for (log) hourly wage **Y**, which depends linearly on job-relevant characteristics **X**:\r\n",
    "\r\n",
    "$$\r\n",
    "Y = \\beta'X + \\epsilon\r\n",
    "$$\r\n",
    "\r\n",
    "Our goals are:\r\n",
    "\r\n",
    "- Predict wages using various characteristics of workers.\r\n",
    "- Assess the predictive performance of a given model using the (adjusted) sample MSE, the (adjusted) sample $R^2$ and the out-of-sample MSE and $R^2$.\r\n",
    "\r\n",
    "Toward answering the latter, we measure the prediction quality of the two models via data splitting:\r\n",
    "\r\n",
    "1. Randomly split the data into one training sample and one testing sample. Here we just use a simple method (stratified splitting is a more sophisticated version of splitting that we might consider).\r\n",
    "2. Use the training sample to estimate the parameters of the Basic Model and the Flexible Model.\r\n",
    "\r\n",
    "Before using the testing sample, we evaluate in-sample fit.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c21d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292211d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"../../data/wage2015_subsample_inference.csv\")\n",
    "n = len(data)\n",
    "# Define alpha values for Lasso\n",
    "alphas = np.linspace(0.1, 0.5, 5)\n",
    "print(alphas)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "np.random.seed(1)\n",
    "random = np.random.randint(0,n, size=math.floor(n))\n",
    "data[\"random\"] = random\n",
    "train = data[ : math.floor(n*4/5)]    # training sample\n",
    "test =  data[ math.floor(n*4/5) : ]   # testing sample\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model using OLS\n",
    "formula_basic = 'lwage ~ sex + exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2'\n",
    "model_basic = smf.ols(formula_basic, data=train).fit()\n",
    "print(\"Number of regressors in the basic model:\", len(model_basic.params))\n",
    "print(model_basic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80017805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible model using OLS\n",
    "formula_flex = 'lwage ~ sex + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)'\n",
    "model_flex = smf.ols(formula_flex, data=train).fit()\n",
    "print(\"Number of regressors in the flexible model:\", len(model_flex.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible model using Lasso, in-sample fit\n",
    "y_train = train['lwage']\n",
    "X_train = pd.get_dummies(train, drop_first=True)\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results = pd.DataFrame({\n",
    "    'alpha': lasso_cv.alphas_,\n",
    "    'mse': np.mean(lasso_cv.mse_path_, axis=1),\n",
    "    'lambda_min': lasso_cv.alpha_,\n",
    "    'nzero': np.sum(lasso_cv.coef_ != 0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "results_sorted = results.sort_values(by='mse')\n",
    "print(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a230c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving optimal alpha\n",
    "alpha_opt=  results_sorted.iloc[0]['alpha']\n",
    "alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "sns.lineplot(data=results_sorted, x='alpha', y='mse')\n",
    "plt.title('Cross-validated MSE for each Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f73a",
   "metadata": {},
   "source": [
    "### Data Splitting: Out-of-sample performance\n",
    "\n",
    "Now that we have seen in-sample fit, we evaluate our models on the out-of-sample performance:\n",
    "\n",
    "1. Use the testing sample for evaluation. Predict the **wage** of every observation in the testing sample based on the estimated parameters in the training sample.\n",
    "2. Calculate the Mean Squared Prediction Error (**MSE<sub>test</sub>**) based on the testing sample for both prediction models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-sample performance\n",
    "# calculating the out-of-sample MSE\n",
    "test = sm.add_constant(test)   #add constant \n",
    "\n",
    "lwage_pred =  model_basic.predict(test) # predict out of sample\n",
    "#print(lwage_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354115cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_test1 = np.sum((lwage_test-lwage_pred)**2)/len(lwage_test)\n",
    "R2_test1  = 1 - MSE_test1/np.var(lwage_test)\n",
    "\n",
    "print(\"Test MSE for the basic model: \", MSE_test1, \" \")\n",
    "print(\"Test R2 for the basic model: \", R2_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible model\n",
    "# estimating the parameters in the training sample\n",
    "flex_results = smf.ols(formula_flex  , data=train).fit()\n",
    "\n",
    "# calculating the out-of-sample MSE\n",
    "lwage_flex_pred =  flex_results.predict(test) # predict out of sample\n",
    "lwage_test = test[\"lwage\"].values\n",
    "\n",
    "MSE_test2 = np.sum((lwage_test-lwage_flex_pred)**2)/len(lwage_test)\n",
    "R2_test2  = 1 - MSE_test2/np.var(lwage_test)\n",
    "\n",
    "print(\"Test MSE for the flexible model: \", MSE_test2, \" \")\n",
    "print(\"Test R2 for the flexible model: \", R2_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flexible model using lasso\n",
    "# get exogenous variables from training data used in flex model\n",
    "flex_results_0 = smf.ols(formula_flex , data=train)\n",
    "X_train = flex_results_0.exog\n",
    "print(X_train.shape)\n",
    "\n",
    "# Get endogenous variable \n",
    "lwage_train = train[\"lwage\"]\n",
    "print(lwage_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e07b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible model using Lasso\n",
    "# get exogenous variables from testing data used in flex model\n",
    "flex_results_1 = smf.ols(formula_flex , data=test)\n",
    "X_test = flex_results_1.exog\n",
    "print(X_test.shape)\n",
    "\n",
    "# Get endogenous variable \n",
    "lwage_test = test[\"lwage\"]\n",
    "print(lwage_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9492bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the out-of-sample MSE\n",
    "reg = linear_model.Lasso(alpha=alpha_opt)\n",
    "lwage_lasso_fitted = reg.fit(X_train, lwage_train).predict( X_test )\n",
    "\n",
    "MSE_lasso = np.sum((lwage_test-lwage_lasso_fitted)**2)/len(lwage_test)\n",
    "R2_lasso  = 1 - MSE_lasso/np.var(lwage_test)\n",
    "\n",
    "print(\"Test MSE for the flexible model: \", MSE_lasso, \" \")\n",
    "print(\"Test R2 for the flexible model: \", R2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062da7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print MSE and R^2\n",
    "\n",
    "table2 = np.zeros((3, 2))\n",
    "table2[0,0] = MSE_test1\n",
    "table2[1,0] = MSE_test2\n",
    "table2[2,0] = MSE_lasso\n",
    "table2[0,1] = R2_test1\n",
    "table2[1,1] = R2_test2\n",
    "table2[2,1] = R2_lasso\n",
    "\n",
    "table2 = pd.DataFrame(table2, columns = [\"$MSE_{test}$\", \"$R^2_{test}$\"], \\\n",
    "                      index = [\"basic reg\",\"flexible reg\",\"lasso regression\"])\n",
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d2dbc",
   "metadata": {},
   "source": [
    "# **1.Frisch-Waugh-Lovell (FWL) Theorem Proof**\n",
    "\n",
    "Given a linear regression model, we aim to demonstrate the FWL theorem using the following elements:\n",
    "\n",
    "- **$y$**: dependent variable vector ($n \\times 1$)\n",
    "- **$D$**: matrix of independent variables of interest ($n \\times k_1$)\n",
    "- **$\\beta_1$**: coefficient vector for $D$ ($k_1 \\times 1$)\n",
    "- **$W$**: matrix of control variables ($n \\times k_2$)\n",
    "- **$\\beta_2$**: coefficient vector for $W$ ($k_2 \\times 1$)\n",
    "- **$u$**: error term vector ($n \\times 1$)\n",
    "\n",
    "The model is represented as:\n",
    "\n",
    "$$ y = D\\beta_1 + W\\beta_2 + u$$\n",
    "\n",
    "---\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "To prove that $\\Psi = \\beta_1$ can be accurately estimated through the regression $e_y = e_D \\Psi + \\varepsilon$, employing the FWL theorem.\n",
    "\n",
    "---\n",
    "\n",
    "## **Proof**\n",
    "\n",
    "### **Step 1: Control for Variables in $W$**\n",
    "\n",
    "First, we calculate the residuals after controlling for $W$:\n",
    "\n",
    "- **Regress $D$ on $W$:** Aim to determine the component of $D$ that is orthogonal to $W$. This is achieved by calculating the residuals $e_D$, using the projection matrix:\n",
    "  \n",
    "  $$M_W = I - W(W'W)^{-1}W'$$\n",
    "  \n",
    "  Thus, the residuals for $D$ are:\n",
    "  \n",
    "  $$e_D = M_W D$$ \n",
    "\n",
    "- **Regress $y$ on $W$:** Similarly, find the component of $y$ not explained by $W$:\n",
    "  \n",
    "  $$e_y = M_W y$$\n",
    "\n",
    "### **Step 2: Estimate $\\Psi$**\n",
    "\n",
    "With the residuals obtained, we proceed to estimate $\\Psi$:\n",
    "\n",
    "- **Regress $e_y$ on $e_D$ by OLS:** \n",
    "\n",
    "  $$ e_y = e_D \\Psi + z $$\n",
    "  \n",
    "  Solving for $\\Psi$, we get:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (e_D'e_D)^{-1}e_D'e_y $$\n",
    "  \n",
    "  Substituting the expressions for residuals into $\\hat{\\Psi}$ yields:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (D'M_W'M_W'D)^{-1}D'M_W'M_Wy $$\n",
    "  \n",
    "  Which simplifies to:\n",
    "  \n",
    "  $$ \\hat{\\Psi} = (D'M_WD)^{-1}D'M_Wy $$\n",
    "\n",
    "And this proof that $\\Psi = \\beta_1$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# **2.Conditional Expectation Function Minimizes Expected Squared Error Proof**\n",
    "\n",
    "## **Problem Statement**\n",
    "\n",
    "Given a random variable $Y$ and a conditioning variable $X$, we consider a relationship of the form:\n",
    "$$ Y = m(X) + \\epsilon $$\n",
    "where:\n",
    "- $m(X) = E[Y | X]$ is the Conditional Expectation Function (CEF) of $Y$ given $X$.\n",
    "- $\\epsilon$ is the error term, representing the deviation of $Y$ from its conditional mean.\n",
    "\n",
    "## **Objective**\n",
    "\n",
    "Our goal is to prove that the function that minimizes the expected squared error:\n",
    "$$ m(X) = \\text{arg}\\min_{g(X)} E[(Y - g(X))^2] $$\n",
    "\n",
    "is indeed:\n",
    "$$ E[(Y - g(X))^2] = E[\\epsilon^2] $$\n",
    "\n",
    "## **Proof**\n",
    "\n",
    "### **Step 1: Expanding the Expected Squared Error**\n",
    "\n",
    "We start by expanding the expected squared difference as follows:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X] + E[Y|X] - g(X))^2] $$\n",
    "\n",
    "By applying the expansion for the square of a sum $(a + b)^2 = a^2 + b^2 + 2ab$, where $a = Y - E[Y|X]$ and $b = E[Y|X] - g(X)$, we obtain:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X])^2] + E[(E[Y|X] - g(X))^2] + 2E[(Y - E[Y|X])(E[Y|X] - g(X))] $$\n",
    "\n",
    "### **Step 2: Simplifying Using the Law of Iterated Expectations**\n",
    "\n",
    "Applying the Law of Iterated Expectations to the mixed term:\n",
    "$$ 2E[(Y - E[Y|X])(E[Y|X] - g(X))] = 0 $$\n",
    "\n",
    "This follows because the expectation of $Y - E[Y|X]$ is zero by definition of the error term $\\epsilon$ (i.e., $Y - E[Y|X] = \\epsilon$ and $E[\\epsilon] = 0$), and thus the cross-term disappears.\n",
    "\n",
    "### **Step 3: Final Reduction**\n",
    "\n",
    "After removing the cross-term, we are left with:\n",
    "$$ E[(Y - g(X))^2] = E[(Y - E[Y|X])^2] + E[(E[Y|X] - g(X))^2] $$\n",
    "\n",
    "Since the second term $E[(E[Y|X] - g(X))^2]$ is always non-negative, it follows that:\n",
    "$$ E[(Y - g(X))^2] \\geq E[(Y - E[Y|X])^2] $$\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "The expected squared error is minimized when $g(X) = E[Y|X]$, demonstrating that the Conditional Expectation Function (CEF) $m(X)$ minimizes the expected squared error:\n",
    "$$ m(X) = \\text{arg}\\min_{g(X)} E[(Y - g(X))^2] $$\n",
    "This conclusively proves that the CEF is the function that minimizes the expected squared error between the predicted values and the actual values of $Y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbd695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
